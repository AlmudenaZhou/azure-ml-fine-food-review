{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focuses on selecting techniques for the final pipeline. For this initial model approach, various techniques are evaluated through cross-validation using a basic Logistic Regression model with default settings:\n",
    "\n",
    "- If one technique demonstrates significantly better performance, it will be incorporated into the pipeline.\n",
    "- If no significant difference is observed, the simplest technique will be selected.\n",
    "\n",
    "Data indexes are tracked because some data is stored as a sparse NumPy array. Although the split was performed using a seed, consistency across library versions or operating systems cannot be guaranteed.\n",
    "\n",
    "The **f1_macro** metric is used for evaluation, as it provides a balanced assessment of false positives and false negatives, ensuring equal consideration for both categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_text_with_all.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "train_index = pd.read_csv('train_index.csv').values[:, 0]\n",
    "test_index = pd.read_csv('test_index.csv').values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.Text.loc[train_index]\n",
    "X_test = df.Text.loc[test_index]\n",
    "y_train = df.Labels.loc[train_index]\n",
    "y_test = df.Labels.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores different algorithms to convert processed text into vectors: CountVectorizer, TF-IDF, and Word2Vec. The Word2Vec training process is handled in the Word2VecTraining notebook, and here, the pre-trained data will be loaded.\n",
    "\n",
    "- **300 features** have been chosen for all models to balance memory usage and avoid overfitting, maintaining a reasonable ratio between rows and columns. The models will be compared based on these 300 features.\n",
    "- For both CountVectorizer and TF-IDF, 1-3 n-grams will be trained. The 2-gram model will capture word pairs like \"not\" and other composite terms, while the 3-gram model will ensure no useful information is overlooked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect3 = CountVectorizer(ngram_range=(1, 3), max_features=300)\n",
    "X_train_cv3 = count_vect3.fit_transform(X_train) \n",
    "# X_val_cv = count_vect.transform(X_val)\n",
    "X_test_cv3 = count_vect3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect2 = CountVectorizer(ngram_range=(1, 2), max_features=300)\n",
    "X_train_cv2 = count_vect2.fit_transform(X_train) \n",
    "# X_val_cv = count_vect.transform(X_val)\n",
    "X_test_cv2 = count_vect2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect1 = CountVectorizer(ngram_range=(1, 1), max_features=300)\n",
    "X_train_cv1 = count_vect1.fit_transform(X_train) \n",
    "# X_val_cv = count_vect.transform(X_val)\n",
    "X_test_cv1 = count_vect1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect2.vocabulary_ == count_vect3.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect2.vocabulary_ == count_vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf3 = TfidfVectorizer(ngram_range=(1, 3), max_features=300)\n",
    "X_train_tfidf3 = tfidf3.fit_transform(X_train)\n",
    "# X_val_tfidf = tfidf.transform(X_val)\n",
    "X_test_tfidf3 = tfidf3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(ngram_range=(1, 2), max_features=300)\n",
    "X_train_tfidf2 = tfidf2.fit_transform(X_train)\n",
    "# X_val_tfidf = tfidf.transform(X_val)\n",
    "X_test_tfidf2 = tfidf2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf1 = TfidfVectorizer(ngram_range=(1, 1), max_features=300)\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X_train)\n",
    "# X_val_tfidf = tfidf.transform(X_val)\n",
    "X_test_tfidf1 = tfidf1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf3.vocabulary_ == tfidf2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf2.vocabulary_ == tfidf1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = pd.read_csv('w2v_window10_train_data.csv', index_col=0)\n",
    "X_test_w2v = pd.read_csv('w2v_window10_test_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_from_models = {'count_vec_ngram1': {'x': X_train_cv1,\n",
    "                                               'y': y_train},\n",
    "                          'tfidf_ngram1': {'x': X_train_tfidf1,\n",
    "                                           'y': y_train},\n",
    "                          'count_vec_ngram2': {'x': X_train_cv2,\n",
    "                                               'y': y_train},\n",
    "                          'tfidf_ngram2': {'x': X_train_tfidf2,\n",
    "                                           'y': y_train},\n",
    "                          'word2vec': {'x': X_train_w2v,\n",
    "                                       'y': y_train}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def generate_cross_scoring_table_from_transf_data(train_data_dict, \n",
    "                                                  pred_model, scoring='f1_macro', cv=10):\n",
    "\n",
    "    all_scores = [cross_val_score(pred_model, train_data['x'], \n",
    "                                  train_data['y'], cv=cv, scoring=scoring)\n",
    "                  for train_data in train_data_dict.values()]\n",
    "\n",
    "    return pd.DataFrame(all_scores, index=train_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count_vec_ngram1</th>\n",
       "      <td>0.730720</td>\n",
       "      <td>0.744704</td>\n",
       "      <td>0.740865</td>\n",
       "      <td>0.744642</td>\n",
       "      <td>0.733056</td>\n",
       "      <td>0.746572</td>\n",
       "      <td>0.741397</td>\n",
       "      <td>0.748263</td>\n",
       "      <td>0.743674</td>\n",
       "      <td>0.738538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_ngram1</th>\n",
       "      <td>0.747909</td>\n",
       "      <td>0.759543</td>\n",
       "      <td>0.754347</td>\n",
       "      <td>0.762461</td>\n",
       "      <td>0.754868</td>\n",
       "      <td>0.759464</td>\n",
       "      <td>0.753718</td>\n",
       "      <td>0.760397</td>\n",
       "      <td>0.758010</td>\n",
       "      <td>0.751561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vec_ngram2</th>\n",
       "      <td>0.734709</td>\n",
       "      <td>0.746985</td>\n",
       "      <td>0.743778</td>\n",
       "      <td>0.748821</td>\n",
       "      <td>0.737387</td>\n",
       "      <td>0.747985</td>\n",
       "      <td>0.744234</td>\n",
       "      <td>0.749215</td>\n",
       "      <td>0.743730</td>\n",
       "      <td>0.741885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_ngram2</th>\n",
       "      <td>0.751512</td>\n",
       "      <td>0.761197</td>\n",
       "      <td>0.756324</td>\n",
       "      <td>0.765519</td>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.760695</td>\n",
       "      <td>0.753588</td>\n",
       "      <td>0.762479</td>\n",
       "      <td>0.759185</td>\n",
       "      <td>0.753557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec</th>\n",
       "      <td>0.819960</td>\n",
       "      <td>0.833779</td>\n",
       "      <td>0.826369</td>\n",
       "      <td>0.834525</td>\n",
       "      <td>0.830219</td>\n",
       "      <td>0.830770</td>\n",
       "      <td>0.827782</td>\n",
       "      <td>0.834607</td>\n",
       "      <td>0.831262</td>\n",
       "      <td>0.830440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4         5  \\\n",
       "count_vec_ngram1  0.730720  0.744704  0.740865  0.744642  0.733056  0.746572   \n",
       "tfidf_ngram1      0.747909  0.759543  0.754347  0.762461  0.754868  0.759464   \n",
       "count_vec_ngram2  0.734709  0.746985  0.743778  0.748821  0.737387  0.747985   \n",
       "tfidf_ngram2      0.751512  0.761197  0.756324  0.765519  0.757312  0.760695   \n",
       "word2vec          0.819960  0.833779  0.826369  0.834525  0.830219  0.830770   \n",
       "\n",
       "                         6         7         8         9  \n",
       "count_vec_ngram1  0.741397  0.748263  0.743674  0.738538  \n",
       "tfidf_ngram1      0.753718  0.760397  0.758010  0.751561  \n",
       "count_vec_ngram2  0.744234  0.749215  0.743730  0.741885  \n",
       "tfidf_ngram2      0.753588  0.762479  0.759185  0.753557  \n",
       "word2vec          0.827782  0.834607  0.831262  0.830440  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "result = generate_cross_scoring_table_from_transf_data(train_data_from_models, \n",
    "                                                       lr, scoring='f1_macro', cv=10)\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word2vec is clearly better than the rest, so we will keep the data and the model from the word2vec for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word2vec'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = \"\"\"0\t1\t2\t3\t4\t5\t6\t7\t8\t9\n",
    "count_vec_ngram1\t0.730720\t0.744704\t0.740865\t0.744642\t0.733056\t0.746572\t0.741397\t0.748263\t0.743674\t0.738538\n",
    "tfidf_ngram1\t0.747909\t0.759543\t0.754347\t0.762461\t0.754868\t0.759464\t0.753718\t0.760397\t0.758010\t0.751561\n",
    "count_vec_ngram2\t0.734709\t0.746985\t0.743778\t0.748821\t0.737387\t0.747985\t0.744234\t0.749215\t0.743730\t0.741885\n",
    "tfidf_ngram2\t0.751512\t0.761197\t0.756324\t0.765519\t0.757312\t0.760695\t0.753588\t0.762479\t0.759185\t0.753557\n",
    "word2vec\t0.819960\t0.833779\t0.826369\t0.834525\t0.830219\t0.830770\t0.827782\t0.834607\t0.831262\t0.830440\"\"\".split(\"\\n\")\n",
    "\n",
    "\n",
    "b = [a1.split(\"\\t\") for a1 in a]\n",
    "\n",
    "columns = b[0]\n",
    "columns\n",
    "c = pd.DataFrame(b[1:])\n",
    "c.index = c[0]\n",
    "c.drop(0, axis=1, inplace=True)\n",
    "c.columns = columns\n",
    "c = c.astype(float)\n",
    "c.mean(axis=1).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle imbalance labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple random undersampling, random oversampling, and SMOTE will be tested to evaluate if these techniques improve the model's performance.\n",
    "\n",
    "A different cross-validation technique will be used to ensure the model is evaluated on data that has not been sampled, avoiding any potential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_us_res, y_us_res = RandomUnderSampler().fit_resample(X_train_w2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_os_res, y_os_res = RandomOverSampler().fit_resample(X_train_w2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_res, y_sm_res = SMOTE().fit_resample(X_train_w2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_models = {'base': None,\n",
    "              'undersampling': RandomUnderSampler(),\n",
    "              'oversampling': RandomOverSampler(),\n",
    "              'smote': SMOTE()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def generate_imb_results_table(pred_model_class, imb_models, X_train_orig, y_train_orig):\n",
    "    all_results = []\n",
    "    for model in imb_models.values():\n",
    "        ss = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "        ind_results = []\n",
    "        for train_index, test_index in ss.split(X_train_orig.values):\n",
    "            x_train = X_train_orig.iloc[train_index]\n",
    "            y_train = y_train_orig.iloc[train_index]\n",
    "            x_test = X_train_orig.iloc[test_index]\n",
    "            y_test = y_train_orig.iloc[test_index]\n",
    "\n",
    "            if model:\n",
    "                x_train_imb, y_train_imb = model.fit_resample(x_train, y_train)\n",
    "            else:\n",
    "                x_train_imb, y_train_imb = x_train, y_train\n",
    "            pred_model = pred_model_class()\n",
    "            pred_model.fit(x_train_imb, y_train_imb)\n",
    "            y_pred = pred_model.predict(x_test)\n",
    "            ind_results.append(f1_score(y_test, y_pred, average='macro'))\n",
    "            \n",
    "        all_results.append(ind_results)\n",
    "    return pd.DataFrame(all_results, index=imb_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_result = generate_imb_results_table(LogisticRegression, imb_models, X_train_w2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.830428</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.832414</td>\n",
       "      <td>0.826815</td>\n",
       "      <td>0.827950</td>\n",
       "      <td>0.828817</td>\n",
       "      <td>0.826058</td>\n",
       "      <td>0.829886</td>\n",
       "      <td>0.828536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>0.804243</td>\n",
       "      <td>0.807803</td>\n",
       "      <td>0.801824</td>\n",
       "      <td>0.802430</td>\n",
       "      <td>0.803316</td>\n",
       "      <td>0.801522</td>\n",
       "      <td>0.803760</td>\n",
       "      <td>0.802825</td>\n",
       "      <td>0.803799</td>\n",
       "      <td>0.803864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>0.804965</td>\n",
       "      <td>0.808338</td>\n",
       "      <td>0.803273</td>\n",
       "      <td>0.802389</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>0.803031</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.803048</td>\n",
       "      <td>0.804639</td>\n",
       "      <td>0.804271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smote</th>\n",
       "      <td>0.810347</td>\n",
       "      <td>0.814086</td>\n",
       "      <td>0.809512</td>\n",
       "      <td>0.807804</td>\n",
       "      <td>0.808141</td>\n",
       "      <td>0.808434</td>\n",
       "      <td>0.809850</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.809418</td>\n",
       "      <td>0.808970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5  \\\n",
       "base           0.830428  0.831779  0.830530  0.832414  0.826815  0.827950   \n",
       "undersampling  0.804243  0.807803  0.801824  0.802430  0.803316  0.801522   \n",
       "oversampling   0.804965  0.808338  0.803273  0.802389  0.803654  0.803031   \n",
       "smote          0.810347  0.814086  0.809512  0.807804  0.808141  0.808434   \n",
       "\n",
       "                      6         7         8         9  \n",
       "base           0.828817  0.826058  0.829886  0.828536  \n",
       "undersampling  0.803760  0.802825  0.803799  0.803864  \n",
       "oversampling   0.805854  0.803048  0.804639  0.804271  \n",
       "smote          0.809850  0.808486  0.809418  0.808970  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, wilcoxon\n",
    "\n",
    "\n",
    "def test_ditr_significantly_greater_than_another(data1, data2, test_type, alpha=0.05):\n",
    "\n",
    "    print(f'----------------------- {test_type.capitalize()} -----------------------')\n",
    "\n",
    "    if test_type == 'ttest':\n",
    "        test_func = ttest_ind\n",
    "    elif test_type == 'wilcoxon':\n",
    "        test_func = wilcoxon\n",
    "    else:\n",
    "        raise ValueError(f'test_type must be ttest or wilcoxon not {test_type}')\n",
    "\n",
    "    statistic, p_value = test_func(data1, data2, alternative='greater')\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        print(\"The mean of the first distribution is significantly\" +\n",
    "            \" greater than the mean of the second one.\")\n",
    "    else:\n",
    "        print(\"The mean of the first distribution is not significantly\" +\n",
    "            \" greater than the mean of the second one.\")\n",
    "        \n",
    "    return statistic, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Ttest -----------------------\n",
      "The mean of the first distribution is significantly greater than the mean of the second one.\n",
      "----------------------- Wilcoxon -----------------------\n",
      "The mean of the first distribution is significantly greater than the mean of the second one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.0, 0.0009765625)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic, p_value = ttest_ind(imb_result.loc['base'],\n",
    "                               imb_result.loc['oversampling'], \n",
    "                               alternative='greater')\n",
    "\n",
    "test_ditr_significantly_greater_than_another(imb_result.loc['base'], \n",
    "                                             imb_result.loc['oversampling'], \n",
    "                                             'ttest')\n",
    "    \n",
    "test_ditr_significantly_greater_than_another(imb_result.loc['base'], \n",
    "                                             imb_result.loc['oversampling'], \n",
    "                                             'wilcoxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Ttest -----------------------\n",
      "The mean of the first distribution is significantly greater than the mean of the second one.\n",
      "----------------------- Wilcoxon -----------------------\n",
      "The mean of the first distribution is significantly greater than the mean of the second one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.0, 0.0009765625)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ditr_significantly_greater_than_another(imb_result.loc['base'], \n",
    "                                             imb_result.loc['undersampling'], \n",
    "                                             'ttest')\n",
    "    \n",
    "test_ditr_significantly_greater_than_another(imb_result.loc['base'], \n",
    "                                             imb_result.loc['undersampling'], \n",
    "                                             'wilcoxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Ttest -----------------------\n",
      "The mean of the first distribution is significantly greater than the mean of the second one.\n",
      "----------------------- Wilcoxon -----------------------\n",
      "The mean of the first distribution is significantly greater than the mean of the second one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.0, 0.0009765625)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ditr_significantly_greater_than_another(imb_result.loc['base'], \n",
    "                                             imb_result.loc['smote'], \n",
    "                                             'ttest')\n",
    "    \n",
    "test_ditr_significantly_greater_than_another(imb_result.loc['base'], \n",
    "                                             imb_result.loc['smote'], \n",
    "                                             'wilcoxon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like for this dataset, the imbalancing techniques worsen the results. Therefore, we are skipping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
